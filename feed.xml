<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://dasayan05.github.io/2024/feed.xml" rel="self" type="application/atom+xml"/><link href="https://dasayan05.github.io/2024/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-28T09:53:46+01:00</updated><id>https://dasayan05.github.io/2024/feed.xml</id><title type="html">ICLR Blogposts 2024</title><subtitle>Home to the 2024 ICLR Blogposts track </subtitle><entry><title type="html">Building Diffusion Model’s theory from ground up</title><link href="https://dasayan05.github.io/2024/blog/diffusion-theory-from-scratch/" rel="alternate" type="text/html" title="Building Diffusion Model’s theory from ground up"/><published>2024-05-07T00:00:00+02:00</published><updated>2024-05-07T00:00:00+02:00</updated><id>https://dasayan05.github.io/2024/blog/diffusion-theory-from-scratch</id><content type="html" xml:base="https://dasayan05.github.io/2024/blog/diffusion-theory-from-scratch/"><![CDATA[<h2 id="introduction">Introduction</h2> <h3 id="motivation">Motivation</h3> <p>Not only generative modeling has been around for decades, few promising model families emerged and dominated the field for several years in the recent past. VAEs<d-cite key="vae_kingma"></d-cite> dominated the generative modelling landscape from 2014 onwards, until GANs<d-cite key="GAN_goodfellow"></d-cite> took off in 2015-16; Normalizing Flows (NF)<d-cite key="normalizingflow"></d-cite> never really made it to the mainstream generative modeling due to its restrictive architectural requirement. However, it is quite clear at this point that the magnitude of impact they made is relatively less than barely 2-3 years of Diffusion Models. It is mostly attributed to one of the seminal papers (by Jonathan Ho et al.<d-cite key="diffusionmodel_ho"></d-cite>), now popularly referred to as “Denoising Diffusion Probabilistic Models” or DDPM. With the exponential explosion of works following DDPM, it is very hard, or rather unnecessary to look beyond this pivotal point.</p> <p>In this article, we look back into the conceptual and theoretical ideas that were in development for a long time, even outside the field of core machine learning. We will show in a later sections that, some of the theoretical ‘pillars’ holding Diffusion Models, have their roots deep into statistical physics and other fields. A significant part of this theory was presented afresh in the ICLR paper<d-cite key="song2021scorebased"></d-cite> (won best paper award). Lastly, even though the ideas presented in this article are quite theoretical, we made our best attempt to convey them with intuitive explanations, diagrams and figures, thereby expanding its potential audience. To encourage further exploration, we provide all codes used in producing the figures (and experiments) of this article in <a href="https://github.com/dasayan05/iclr24_blog_code"><span style="color:blue;">this repository</span></a>.</p> <p>This article notes that, historically, there were two distinct roads of development that merged in order for modern diffusion models to emerge – “scalable estimation of score” and “using the score for generative modelling”. The former is relatively short, while the latter traces its origin back to ~1900, if not earlier. This article explores these two paths independently – the latter one first while assuming the knowledge of the former. Rest of this introductory section is spent on defining the general modelling problem and the very notion of ‘score’ – the primary quantity of interest. The next section deals with how we can use score in generative modelling, assuming access to an oracle for the true score. The last section dives solely into the problem of estimating the score in a scalable manner. It is worth mentioning that, in this article, we explain only the “sufficient and necessary” concepts needed to build the diffusion model framework and hence may not directly resemble the typical formalism seen in most papers.</p> <h3 id="generative-modeling">Generative Modeling</h3> <p>The problem of generative modeling, in most cases, is posed as <em>parametric density estimation</em> using a finite set of samples \(\{ x^{(n)} \}_{n=1}^N\) from a “true but unknown” data distribution \(q_{data}(x)\). With a suitable model family chosen as \(p_{\theta}(x)\), with unknown parameters \(\theta\), the problem boils down to maximizing the average (log-)likelihood (w.r.t \(\theta\)) of all the samples under the model</p> \[\theta^* = arg\max_{\theta} \mathbb{E}_{x \sim q_{data}(x)} \left[ \log p_{\theta}(x) \right] \approx arg\max_{\theta} \frac{1}{N} \sum_{n=1}^N \log p_{\theta}(x^{(n)})\] <p>It turned out however, that defining an arbitrary parametric density \(p_{\theta}(x)\) is not as easy as it looks. There was one aspect of \(p_{\theta}\) that is widely considered to be the evil behind this difficulty – <em>the normalizing constant</em> that stems from the axiom of probability</p> \[p_{\theta}(x) = \frac{\tilde{p}_{\theta}(x)}{\color{purple} \int_x \tilde{p}_{\theta}(x)}\] <h3 id="existing-frameworks">Existing Frameworks</h3> <p>It was understood quite early on that any promising generative model family must have one property – <em>ease of sampling</em>, i.e. generating new data samples. Sampling was so essential to generative modeling, that the model families that followed were all geared towards effective sampling, even if it was at the expense of other not-so-important properties. It was also well understood that there was one common underlying principle most effective for crafting “sampling-centric” generative models – <em>transforming simple probability densities</em>. This formed the backbone of every single generative model family so far; be it VAEs, GANs or NFs, their generative process is a density transformation of this form</p> \[x = f_{\theta}(z),\text{ where } z \sim \mathcal{N}(0, I)\] <p>that suggests to start with a simple density (often just standard normal) followed by a functional transformation \(f_{\theta}\), typically a neural network with parameters \(\theta\). For VAEs, the function \(f_{\theta}\) is the decoder; for GANs, it’s the generator network and for NFs, it’s the entire flow model. It is to be noted however, that the way they differ is mostly <em>how they are trained</em>, which may involve more parametric functions (e.g. VAE’s encoder or GAN’s discriminator) and additional machinery. This way of building generative models turned out to be an effective way of sidestepping the notorious normalizing constant.</p> <h3 id="diffusion-is-no-different">Diffusion is no different</h3> <p>Diffusion Models, at its core, follow the exact same principle, but with a slightly clever design. For diffusion models, the transformation \(f_{\theta}\) is rather complicated. It is a sequence of invocations of a neural function (denoted as \(s_{\theta}\)) along with some additional computation (denoted as \(g(\cdot)\))</p> <p>\begin{equation} \label{eq:diffusion_general_parametric_structure} x = g_1(g_2(g_3(\cdots z \cdots, s_{\theta}), s_{\theta}), s_{\theta}), \text{ where } z \sim \mathcal{N}(0, I) \end{equation}</p> <p>This is a big difference between Diffusion Models and other generative model families. Prior generative families tried to learn the exact transformation directly via one parametric neural function \(f_{\theta}\). Diffusion Models on the other hand, try to learn \(s_{\theta}\), a quantity very <em>fundamental and intrinsic</em> to any true data distribution \(q_{data}(x)\). The quantity in question has historically been called the “<em>Score</em>”.</p> <h3 id="the-score">The ‘Score’</h3> <p>The term ‘Score’ is simply defined as the <em>gradient of the log-density of a distribution</em>, i.e. \(\nabla \log p(\cdot)\). In statistics, it is also known (but not very popular) as the ‘Informant’. One might argue that ‘Score’ is rather a strange name for such a quantity. It so happened that the origin of this term can be traced<d-footnote>Thanks to <a href="https://stats.stackexchange.com/a/342374">this</a> StackOverflow answer by @ben</d-footnote> to a 1935 paper<d-cite key="fisher1935detection"></d-cite> by Ronald Fisher, where he used the term in a very generic sense in order to “rank” some quantities. In the context of diffusion models however, we stick to the modern definition of score. The <em>true score</em> of our data distribution is therefore defined as the gradient of the log of <em>true density</em> of data, w.r.t the data variable</p> <p>\begin{equation} \label{eq:data_score_defn} \nabla_x \log q_{data}(x) \triangleq s(x) \end{equation}</p> <p>The quantity in Eq.\eqref{eq:data_score_defn} is unknown, just like the true data density \(q_{data}(x)\). It does have a meaning though: the “<em>true score</em>” refers to the <em>direction of steepest increase</em> in log-likelihood at any given point in the data space. See the gray arrows in the figure below.</p> <center> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/score_def-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/score_def-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/score_def-1400.webp"/> <img src="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/score_def.png" class="col-8" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </center> <p>Simply, at a point \(x\), it tell us the best direction to step into (with little step-size \(\delta\)) if we would like to see a point \(x'\) with slightly higher likelihood</p> <p>\begin{equation} \label{eq:naive_score_steps} x’ = x + \delta \cdot \left. \nabla_x \log q_{data}(x) \right|_{x = x} \end{equation}</p> <p>Please note that this stems just from the definition of the gradient operator \(\nabla\) in score. If you are familiar with gradient descent, you may find conceptual resemblance.</p> <p>Now, there are two burning questions here:</p> <ol> <li>Considering we have access to the true score, is Eq.\eqref{eq:naive_score_steps} enough to define a generative process with appropriate convergence guarantee ?</li> <li>How do we actually get the true score ?</li> </ol> <p>The following two sections answer these questions respectively. Luckily, as we now understand that these two questions are somewhat decoupled, that they can be studied independently. The first section analyzes the first question, <em>assuming</em> we have access to the true score \(\nabla_x \log q_{data}(x)\). The second section explores how to get the true score, or rather, an approximation of it.</p> <h2 id="generative-modeling-with-scores">Generative Modeling with Scores</h2> <p>As explained before, we would like to sample from the true data distribution \(q_{data}(x)\) but all we have access to (we assume) is its score \(s(x)\) as defined in Eq.\eqref{eq:data_score_defn}. One may define a naive generative process as the iterative application of Eq.\eqref{eq:naive_score_steps}. Intuitively, it is very similar to gradient descent, where we greedily climb the log-density surface to attain a local maxima. If so, we can already see a possible instance of the general structure of Diffusion’s generative process as hinted in Eq.\eqref{eq:diffusion_general_parametric_structure}, with \(g(\cdot)\) being</p> \[g(z, s(\cdot)) = z + \delta \cdot s(z) = z + \delta \cdot \nabla_x \log q_{data}(x)\] <p>With a little reshuffling of Eq.\eqref{eq:naive_score_steps} and considering \(\delta \rightarrow 0\), one can immediately reveal the underlying ODE<d-footnote>Ordinary Differential Equations, or ODEs describe how a process evolves over time by its infinitesimal change.</d-footnote> that describes the infinitesimal change</p> <p>\begin{equation} \label{eq:ode_with_score} dx = \nabla_x \log q_{data}(x) dt \end{equation}</p> <p>BUT, please note that this is only an intuitive attempt and is entirely based on the definition of score. It possesses <strong>absolutely no guarantee</strong> that this process can converge to samples from the true data distribution. In fact, this process is <strong>greedy</strong>, i.e. it only seeks to go uphill, converging exactly at the <em>modes</em><d-footnote>Local maxima of probability density</d-footnote>. You can see the below figure that shows the samples \(x\) subjected to the process in Eq.\eqref{eq:ode_with_score} and its density \(p_t(x)\) evolving over time. The density in red is the target density whose score (we assume we know it) is being used.</p> <center> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/greedy_wo_noise.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/greedy_wo_noise.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/greedy_wo_noise.gif-1400.webp"/> <img src="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/greedy_wo_noise.gif" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </center> <p>In this case, at \(t=\infty\), all samples will converge to the state with <em>the highest</em> likelihood (i.e. exactly a the center). This isn’t really desirable as it doesn’t “explore” at all. Just like any other sampling algorithm, we need noise injection !</p> <h3 id="langevin-equation-and-brownian-motion">Langevin Equation and Brownian Motion</h3> <p>Turned out that this problem was explored long ago<d-cite key="lemons1997paul"></d-cite> in molecular dynamics by french physicist Paul Langevin in the context of analyzing movements of particles suspended in a fluid. He described the overall dynamics of particles, i.e how the position of the particle changes over time $t$ when in a <em>potential energy</em> field \(U(x)\)</p> <p>\begin{equation} \label{eq:original_langevin_dyn} dx = - \nabla_x U(x) dt + \sqrt{2} dB_t \end{equation}</p> <p>The term \(dB_t\) is called “Brownian Motion” and is effectively the source of noise – we will talk about this later in this subsection. Energy is considered “bad”, i.e. particles do not want to stay in a state with high energy. So they try to go downhill and settle in low-energy states using the gradient of the energy surface. The langevin equation (i.e. Eq.\eqref{eq:original_langevin_dyn}) happened to provide sufficient “exploration” abilities so that the particles visit states with probability \(\propto e^{-U(x)}\). This suggests that we can treat “negative energy” as log-likelihood</p> \[q_{data}(x) \propto e^{-U(x)} \implies \log q_{data}(x) = -U(x) + C \implies \nabla_x \log q_{data}(x) = - \nabla_x U(x)\] <p>By using the above substitution into the langevin equation, we can move out of physics and continue with out ML perspective</p> <p>\begin{equation} \label{eq:langevin_dyn} dx = \nabla_x \log q_{data}(x) dt + \sqrt{2} dB_t \end{equation}</p> <p>Note that this isn’t very different from our “intuitive” and greedy process in Eq.\eqref{eq:ode_with_score}, except for the noise term \(dB_t\) and a strange \(\sqrt{2}\). But this makes a difference! The brownian motion is an old construct from particle physics to describe random motion of particles in fluid/gas. It is simply a gaussian noise with infinitesimally small variance<d-footnote>In practice, the smaller step you take, the small noise you get.</d-footnote></p> \[dB_t = \mathcal{N}(0, dt) \implies dB_t = \sqrt{dt} \cdot z,\text{ where } z \sim \mathcal{N}(0, I)\] <p>With that, we can simulate our new langevin equation <em>with noise</em> (i.e. Eq.\eqref{eq:langevin_dyn}) just like the noiseless case. You can see now that the noise is keeping the process from entirely converging into the mode. If you notice carefully, we have added a little “tail” to each point to help visualize their movement.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/langevin_dyn_basic.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/langevin_dyn_basic.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/langevin_dyn_basic.gif-1400.webp"/> <img src="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/langevin_dyn_basic.gif" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="fokker-planck-equation">Fokker-Planck Equation</h3> <p>The simulation is convincing; but it’d be even better if we can <em>theoretically verify</em> that the process in Eq.\eqref{eq:langevin_dyn} indeed converges to \(q_{data}(x)\). The key to this proof is figuring out \(p_t(x)\) and making sure that it stabilizes as \(t\rightarrow \infty\), i.e. \(p_{\infty}(x) = q_{data}(x)\). It turned out that a stochastic process of the form \(dx = \mu_t(x) dt + \sigma_t(x) dB_t\), acting on a random variable \(x\), induces a time-varying distribution that can be described by this ODE</p> <p>\begin{equation} \frac{\partial}{\partial t}p_t(x) = -\frac{\partial}{\partial x} \Big[ p_t(x)\mu_t(x) \Big] + \frac{1}{2} \frac{\partial^2}{\partial x^2} \Big[ p_t(x) \sigma^2_t(x) \Big] \end{equation}</p> <p>This is a well celebrated result know as the “Fokker-Planck equation” that even predates the Langevin Equation. So, the solution of this ODE is exactly what we are seeing in the above figure (middle). One can easily verify the convergence of Eq.\eqref{eq:langevin_dyn} by first observing \(\mu_t(x) = \nabla_x \log q_{data}(x), \sigma_t(x) = \sqrt{2}\) and then using \(\frac{\partial}{\partial t} p_{\infty}(x) = \frac{\partial}{\partial t} q_{data}(x) = 0\).</p> \[\begin{eqnarray*} \frac{\partial}{\partial t}p_{\infty}(x) &amp;=&amp; -\frac{\partial}{\partial x} \Big[ p_{\infty}(x) \nabla_x \log q_{data}(x) \Big] + \frac{(\sqrt{2})^2}{2} \frac{\partial^2}{\partial x^2} \Big[ p_{\infty}(x) \Big] \\ \frac{\partial}{\partial t} q_{data}(x) &amp;=&amp; -\frac{\partial}{\partial x} \Big[ q_{data}(x) \nabla_x \log q_{data}(x) \Big] + \frac{(\sqrt{2})^2}{2} \frac{\partial^2}{\partial x^2} \Big[ q_{data}(x) \Big] \\ 0 \text{ (LHS)} &amp;=&amp; -\frac{\partial}{\partial x} \Big[ \nabla_x q_{data}(x) \Big] + \frac{\partial}{\partial x} \Big[ \nabla_x q_{data}(x) \Big] = 0\text{ (RHS)} \end{eqnarray*}\] <p>The LHS holds due to the fact that after a long time (i.e. \(t = \infty\)) the distribution stabilizes<d-footnote>It's called a "stationary or equilibrium distribution"</d-footnote>. Please also note that the proof above is for the 1 dimensional case and included for illustrative purpose only – the general case is slightly more complicated.</p> <p>So, we’re all good. Eq.\eqref{eq:langevin_dyn} is a provable way of sampling given we have access to the true score. In fact, the very work<d-cite key="song2019generative"></d-cite> (by Song et al.) that immediately precedes DDPM, used exactly Eq.\eqref{eq:langevin_dyn} in its discrete form</p> <p>\begin{equation} x_{t+\delta} = x_t + \delta \cdot \nabla_x \log q_{data}(x) + \sqrt{2\delta} \cdot z \end{equation}</p> <p>where \(\delta\) (a small constant) is used as a practical proxy for the theoretical \(dt\).</p> <p>If you are already familiar with Diffusion Models, specifically their reverse process, you might be scratching your head. That is because, the generative process in Eq.\eqref{eq:langevin_dyn} isn’t quite same as what modern diffusion models do. We need to cross a few more hurdles before we get there.</p> <h3 id="a-probability-path">A probability path</h3> <p>More than just a proof, the Fokker-Planck ODE provides us with a key insight – i.e. gradually transforming one distribution into another is equivalent to traveling (over time) on a “path” in the <em>space of probability distributions</em>. Imagine a space of all possible probability distributions \(p\)<d-footnote>While each distribution vary in space (i.e. $x$) too, let's hide it for now and imagine them to be just a vectors.</d-footnote>. The Fokker-Planck ODE for Eq.\eqref{eq:langevin_dyn}, therefore, represents a specific dynamics on this probability space whose solution trajectory \(p_t\) ends at \(q_{data}\) at \(t = \infty\).</p> <p>Speaking of ODEs, there is something we haven’t talked about yet – the initial distribution at \(t=0\), i.e. \(p_0\). In the simulation above, I quietly used a standard normal \(\mathcal{N}(0, I)\) as starting distribution<d-footnote>You can notice this if you carefully see the first few frames of the animation.</d-footnote> without ever discussing it. Turns out that our Fokker-Planck ODE does not have any specific requirement for \(p_0\), i.e. it always converges to \(p_{\infty} = q_{data}\) no matter where you start. Here’s an illustration that shows two different starting distributions \(p_0\) and both of their “paths” over time, i.e. \(p_t\) in probability space ultimately converges to \(q_{data}\).</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/fokker-plank-multiple.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/fokker-plank-multiple.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/fokker-plank-multiple.gif-1400.webp"/> <img src="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/fokker-plank-multiple.gif" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>So theoretically, given the score function \(\nabla_x \log q_{data}(x)\) of a target distribution \(q_{data}(x)\), one can “travel to” it from <em>any</em> distribution. However, keeping in mind our need for <em>sampling</em>, it’s best to choose an initial distribution that is sampling-friendly. Strictly speaking, there are couple of reasonable choices, but the diffusion model community ended up with the <em>Isotropic Gaussian</em> (i.e. \(\mathcal{N}(0, I)\)). This is not only due to its goodwill across machine learning and statistics, but also the fact that in the context of SDEs with Brownian motions<d-footnote>Remember, they are infinitesimal gaussian noises.</d-footnote>, Gaussians arise quite naturally.</p> <h3 id="estimating-the-score-is-hard">Estimating the “score” is hard</h3> <p>So far what we’ve talked about, is just the <em>generative process</em> or as diffusion model literature calls it, the “reverse process”. But we haven’t really talked about the “forward process” yet, in case you are familiar with it. The forward process, in simple terms, is an <em>ahead-of-time description</em> of the “probability path” that reverse process intends to take. But the question is, why do we need to know the path ahead of time – the reverse process seems quite spontaneous<d-footnote>In the sense that, given a score function, it just travels to the correct target distribution on its own.</d-footnote>, no ? Sadly, it can’t be answered with theory alone.</p> <p>The problem lies in Eq.\eqref{eq:langevin_dyn} – let’s write it again with a little more verbosity</p> <p>\begin{equation} dx_t = \nabla_x \left. \log q_{data}(x) \right|_{x = x_t}\ dt + \sqrt{2} dB_t \end{equation}</p> <p>Even though we wished to estimate \(\nabla_x \log q_{data}(x)\vert_{x = x_t}\) with neural network \(s_{\theta}(x = x_t)\), this turned out to be <strong>extremely hard</strong> in practice<d-cite key="song2019generative"></d-cite>. It was understood that one neural network is not enough to capture the richness of the score function at all values of \(x\). There were two options before the us – one, make the neural network expressive enough, or second, learn the network <strong>only where it’s needed</strong>. The community settled on the second one because it was easier to solve.</p> <p>So, what some of the pioneering works did, is first fixing a path<d-footnote>On probability space, like we showed above</d-footnote> and then learning the score only <em>on that path</em>. It’s all about specializing the neural network \(s_{\theta}(x_t, t)\) over \(t \in [0, \infty]\). The neural score estimator is capable of producing the right score if we provide the time \(t\), which we can of course. We will see in <a href="#estimating-the-score">the next section</a> that, to learn a score of any distribution, we need samples from it. This begs the question: how do we get samples \(x_t\) (for all \(t\)) for training purpose ? It certainly can’t be with Eq.\eqref{eq:langevin_dyn} since it requires the score. The answer is, we need to run this process in the other way – this is what Diffusion Models call the “Forward Process”.</p> <h3 id="the-forward-process">The “forward process”</h3> <p>Going <em>the other way</em> requires us to run a simulation to go from \(q_{data}(x)\) at \(t=0\) to \(t=\infty\), just the opposite of the animation above. Recall that we already saw how to do this. To go to any distribution at \(t=\infty\), all you need is its score and the langevin equation. So how about we start from \(q_0 = q_{data}(x)\) this time<d-footnote>Do you remember that starting point doesn't matter !</d-footnote> and run the langevin simulation again with a <em>known</em> end target \(q_{\infty} = \mathcal{N}(0, I)\) ?</p> \[\begin{eqnarray} dx &amp;=&amp; \nabla_x \log \mathcal{N}(0, I) dt + \sqrt{2} dB_t \\ \label{eq:forward_sde} &amp;=&amp; -x dt + \sqrt{2 dt} z \end{eqnarray}\] <p>It is interesting to note that due to the target distribution being known in its closed form, we do not see any awkward scores dangling around. The score of \(\mathcal{N}(0, I)\) is simply \(-x\)<d-footnote>We encourage the reader to verify this on their own as an exercise.</d-footnote>. The discretized version of Eq.\eqref{eq:forward_sde}, i.e.</p> \[\begin{eqnarray*} x_{t+dt} &amp;=&amp; x_t - x_t \cdot dt + \sqrt{2 dt}\ z \\ &amp;=&amp; (1 - dt) x_t + \sqrt{2 dt}\ z \end{eqnarray*}\] <p>.. may resemble DDPM’s<d-cite key="diffusionmodel_ho"></d-cite> forward process<d-footnote>Hint: compare $dt$ with DDPM's $\beta_t$.</d-footnote>.</p> <blockquote> <p>NOTE: A little subtlety here that we only fixed the <em>end point</em> of the forward process, but not the <em>exact path</em>. It seems that running the langevin equation in the forward direction chose one path on its own. Turns out that this is the “isotropic path” where all dimensions of the variable \(x\) evolves in time the exact same way. Some works<d-cite key="das2023spdiffusion"></d-cite><d-cite key="hoogeboom2023blurring"></d-cite> recently uncovered <em>non-isotropic</em> diffusion, where it is indeed possible to travel on other paths. But this is outside the scope of this article.</p> </blockquote> <p>We can simulate the above equation just like we did in the reverse process, in order to get samples \(x_t \sim q_t\). Below we show simulation of the forward process</p> <center> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/forward_process_2.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/forward_process_2.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/forward_process_2.gif-1400.webp"/> <img src="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/forward_process_2.gif" class="col-10" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </center> <p>While it is true that the reverse process in inherently sequential due to the arbitrary nature of the score, the forward process (in Eq.\eqref{eq:forward_sde}) is entirely known and hence can be exploited for easing the sequentiality. We can see a way out if we try to simplify<d-footnote>We use the standard assumption of $dt^2 = 0$.</d-footnote> the expression for \(x_{t+2dt}\) using \(x_{t+dt}\)</p> \[\begin{eqnarray*} x_{t+2dt} &amp;=&amp; (1 - dt) {\color{blue} x_{t+dt}} + \sqrt{2dt}\ z_2 \\ &amp;=&amp; (1 - dt) {\color{blue} \left[(1 - dt) x_t + \sqrt{2 dt}\ z_1\right]} + \sqrt{2dt}\ z_2 \\ &amp;=&amp; (1 - 2dt) x_t + \sqrt{2dt(1-dt)^2 + 2dt}\ z_{12} \\ &amp;=&amp; (1 - 2 \cdot dt) x_t + \sqrt{2 \cdot 2dt}\ z_{12} \\ \implies x_{t+2dt} &amp;\sim&amp; \mathcal{N}((1 - 2 \cdot dt) x_t, 2 \cdot 2dt I) \end{eqnarray*}\] <p>The above simplification suggests that we can jump to any time \(t\), without going through the entire sequence, in order to sample \(x_t \sim q_t\). In fact, \(q_t(x_t\vert x_0)\) is gaussian ! This result opens up an interesting interpretation – generating \(x_0 \sim q(x_0 \vert x_t)\) can be interpreted as solving a “gaussian inverse problems”, which we explore <a href="#denoising-as-inverse-problem">in a later section</a>.</p> <p>All good for now, but there is one more thing we need to deal with.</p> <h3 id="finite-time--the-schedule">Finite time &amp; the “schedule”</h3> <p>What we discussed so far, i.e. the forward and reverse process, require infinite time to reach its end state. This is a direct consequence of using the langevin equation. That, of course, is unacceptable in practice. But it so happened that there exists quite an elegant fix, which is well known to mathematics – we simply <em>re-define what time means</em>. We may choose a re-parameterization of time as, for example, \(t' = \mathcal{T}(t) = 1 - e^{-t} \in [0, 1]\)<d-footnote>You can see $t = 0 \implies t' = 0$ and $t = \infty \implies t' = 1$. Hence we converted the range $[0, \infty]$ to $[0, 1]$.</d-footnote>. Plugging \(dt = \mathcal{T}'(t)^{-1} dt' = e^t dt'\)<d-footnote>One can easily see that $t' = 1 - e^{-t} \implies dt' = e^{-t} dt \implies dt = e^t dt'$.</d-footnote> into the forward equation brings us even closer to DDPM’s forward process</p> \[x_{t' + dt'} = (1 - {\color{blue}e^t dt'}) x_t + \sqrt{2 {\color{blue}e^t dt'}}\ z\] <p>This suggests that in the world where time runs from \(t' = 0 \rightarrow 1\), we need to <em>escalate</em> the forward process by replacing \(dt\) with \(e^t dt'\). The quantity \(\mathcal{T}'(t)^{-1} dt' = e^t dt'\) is analogous to what diffusion models <d-cite key="diffusionmodel_ho"></d-cite><d-cite key="pmlr-v37-sohl-dickstein15"></d-cite> call a “schedule”. Recall that DDPM uses a small but increasing<d-footnote>$e^t dt'$ is small because of $dt'$, while increasing because of $e^t$.</d-footnote> “schedule” \(\beta_t\).</p> <center> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/ddpm_forward_kernel-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/ddpm_forward_kernel-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/ddpm_forward_kernel-1400.webp"/> <img src="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/ddpm_forward_kernel.png" class="col-6 z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </center> <p>Of course, our choice of the exact value of end time (i.e. \(t' = 1\)) and the re-parameterization \(\mathcal{T}\) are somewhat arbitrary. Different choices of \(\mathcal{T}\), and consequently \(\mathcal{T}'(t)^{-1} dt'\) lead to different schedules (e.g. linear, cosine etc.).</p> <blockquote> <p>NOTE: Choosing a different schedule does not mean the process takes a different path on the probability space, it simply changes its <em>speed</em> of movement over time towards the end state.</p> </blockquote> <h4 id="summary">Summary</h4> <p>To summarize, in this section, we started with the definition of ‘score’ and arrived at a stochastic process (thanks to an old result by Langevin) that, at infinite time, converges to the density associated with the score. We saw that this process is provably correct and can be interpreted as a “path” on the probability space. We argued that due to the difficulty of score estimation everywhere along the path, we need samples at the intermediate time \(t\) in order to specialize the score estimates. To do that, we had to travel backwards on the path, which can be done in closed form. We also saw how this process, even though theoretically takes infinite time, can be shrunk down to a finite interval, opening up a design choice known as “schedules”.</p> <h2 id="estimating-the-score">Estimating the Score</h2> <p>The last chapter, while explaining the “sampling” part of score-based diffusion models, assumed that we have access to the true score \(\nabla_x \log q_{data}(x)\) via some oracle. That is, of course, untrue in practice. In fact, accessing the true score for any arbitrary distribution is just not possible<d-footnote>We can only have access to the true score for distributions with closed-form, e.g. Gaussian.</d-footnote>. So the way forward, as mentioned before, is to estimate/learn it with a parametric neural network \(s_{\theta}(x)\). Recall however, that all we have access to is samples from \(q_{data}(x)\).</p> <p>If curious enough, one may question how realistic it is to estimate the score \(\nabla_x \log q_{data}(x)\), while we can NOT usually estimate the density \(q_{data}(x)\) itself ? After all, it is a quantity derived from the density ! The answer becomes clear once you make the <em>normalization constant</em> explicit</p> \[\begin{eqnarray*} \nabla_x \log q_{data}(x) &amp;=&amp; \nabla_x \log \frac{\tilde{q}_{data}(x)}{\int_{x} \tilde{q}_{data}(x) dx} \\ &amp;=&amp; \nabla_x \log \tilde{q}_{data}(x) - {\color{red}\nabla_x \log \int_{x} \tilde{q}_{data}(x) dx} \\ &amp;=&amp; \nabla_x \log \tilde{q}_{data}(x) \end{eqnarray*}\] <p>The part in red is zero due to not having dependence on \(x\). So, the score, very cleverly <strong>sidesteps the normalization constant</strong>. This is the reason score estimation gained momentum in the research community.</p> <h3 id="implicit-score-matching">Implicit Score Matching</h3> <p>The first notable attempt of this problem was by Aapo Hyvärinen<d-cite key="hyvarinen05a"></d-cite> back in 2005. His idea was simply to start from a loss function that, when minimized, leads to an estimator of the true score</p> <p>\begin{equation} J(\theta) = \frac{1}{2} \mathbb{E}_{x\sim q_{data}(x)}\Big[ \vert\vert s_{\theta}(x) - \nabla_x \log q_{data}(x) \vert\vert^2 \Big] \end{equation}</p> <p>It is simply an \(L_2\) loss between a parametric model and the true score, weighted by the probability of individual states (hence the expectation). But of course, it is not computable in this form as it contains the true score. Hyvärinen’s contribution was to simply show that, theoretically, the minimization problem is equivalent when the loss function is</p> <p>\begin{equation} \label{eq:impl_score_match} J_{\mathrm{I}}(\theta) = \mathbb{E}_{x\sim q_{data}(x)}\Big[ \mathrm{Tr}(\nabla_x s_{\theta}(x)) + \frac{1}{2} \vert\vert s_{\theta}(x) \vert\vert^2 \Big] \end{equation}</p> <p>In the literature, this is known as the “<em>Implicit Score Matching</em>”. The derivation is relatively simple and only involves algebraic manipulations – please see Appendix A of <d-cite key="hyvarinen05a"></d-cite>. The remarkable nature of this result stems from the fact that \(J_{\mathrm{I}}\) no longer contains the true score. The only dependency on \(q_{data}\) is via the expectation, which can be approximated by sample average over our dataset.</p> <p>But the key challenge with Implicit Score Matching was the \(\mathrm{Tr}(\nabla_x s_{\theta}(x))\) term, i.e. the trace of the hessian of the neural score model, which is costly to compute. This prompted several follow-up works for the race towards scalable score matching, one of which (namely De-noising score matching) is used in Diffusion Models till this day.</p> <p>For the sake of completeness, I would like to mention the work of Yang Song et al.<d-cite key="song2020sliced"></d-cite> around 2019, that proposed an engineering trick to alleviate the hessian computation. They simply used the “Hutchinson Trace estimator”<d-footnote>A stochastic way of computing trace: $\mathrm{Tr}(M) = \mathbb{E}_{v\sim p_v} \Big[ v^T M v \Big]$, where $p_v$ can be a lot of distributions, most notably $\mathcal{N}(0, I)$.</d-footnote> to replace the \(\mathrm{Tr}(\cdot)\) in Eq.\eqref{eq:impl_score_match}, which eased the computation a bit. This approach however, did not end up being used in practice.</p> <h3 id="denoising-score-matching">Denoising Score Matching</h3> <p>The most valuable contribution came from Vincent Pascal in 2011, when he showed <d-cite key="vincent2011connection"></d-cite> that the score matching problem has yet another equivalent objective, which was called “Denoising” score matching</p> <p>\begin{equation} \label{eq:deno_score_match} J_{\mathrm{D}}(\theta) = \mathbb{E}_{x\sim q_{data}(x), \epsilon\sim\mathcal{N}(0, I)}\left[ \frac{1}{2} \left|\left| s_{\theta}(\ \underbrace{x + \sigma\epsilon}_{\tilde{x}}\ ) - (- \frac{\epsilon}{\sigma}) \right|\right|^2 \right] \end{equation}</p> <p>We deliberately wrote it in a way that exposes its widely accepted interpretation. Denoising score matching simply adds some <em>known</em> noise \(\sigma\epsilon\) to the datapoints \(x\) and learns (in mean squeared sense), from the “noisy” point \(\tilde{x}\), the direction of comeback, i.e. \((-\epsilon)\), scaled by \(\frac{1}{\sigma}\). In a way, it acts like a “de-noiser”, hence the name. It is theoretically guaranteed <d-cite key="vincent2011connection"></d-cite> that \(J_{\mathrm{D}}\) leads to an unbiased estimate of the true score. Below we show a visualization of the score estimate as it learns from data.</p> <center> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/deno_score_learning.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/deno_score_learning.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/deno_score_learning.gif-1400.webp"/> <img src="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/deno_score_learning.gif" class="col-10" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </center> <p>A little algebraic manipulation of Eq.\eqref{eq:deno_score_match}, demonstrated by Ho et al. <d-cite key="diffusionmodel_ho"></d-cite>, leads to an equivalent form which turned out to be training friendly.</p> \[\begin{eqnarray} J_{\mathrm{D}}(\theta) &amp;=&amp; \mathbb{E}_{x\sim q_{data}(x), \epsilon\sim\mathcal{N}(0, I)}\left[ \frac{1}{2\sigma^2} \left|\left| {\color{blue} - \sigma s_{\theta}}(\tilde{x}) - \epsilon \right|\right|^2 \right] \\ &amp;=&amp; \mathbb{E}_{x\sim q_{data}(x), \epsilon\sim\mathcal{N}(0, I)}\left[ \frac{1}{2\sigma^2} \left|\left| {\color{blue} \epsilon}_{\theta}(\tilde{x}) - \epsilon \right|\right|^2 \right]\label{eq:deno_eps_match} \end{eqnarray}\] <p>We simply change the <em>interpretation</em> of what the network learns. In this form, the “noise estimator” network learns <em>just</em> the original pure gaussian noise vector \(\epsilon\) that was added while crafting the noisy sample. So, from a noisy sample, the network \(\epsilon_{\theta}\) learns roughly an unit variance direction that points towards the clean sample.</p> <p>There is yet another re-interpretation of Eq.\eqref{eq:deno_score_match} that leads to a slightly different perspective</p> \[\begin{eqnarray} J_{\mathrm{D}}(\theta) &amp;=&amp; \mathbb{E}_{x\sim q_{data}(x), \epsilon\sim\mathcal{N}(0, I)}\left[ \frac{1}{2\sigma^4} \left|\left| {\color{blue}\tilde{x} + \sigma^2 s_{\theta}}(\tilde{x}) - (\underbrace{\tilde{x} - \sigma\epsilon}_{x}) \right|\right|^2 \right] \\ &amp;=&amp; \mathbb{E}_{x\sim q_{data}(x), \epsilon\sim\mathcal{N}(0, I)}\left[ \frac{1}{2\sigma^4} \left|\left| {\color{blue} x_{\theta}}(\tilde{x}) - x \right|\right|^2 \right]\label{eq:deno_endpoint_match} \end{eqnarray}\] <p>Eq.\eqref{eq:deno_endpoint_match} shows, that instead of the noise direction towards clean sample, we can also have the clean sample directly as a learning target. This is like doing “denoising” in its true sense. We will get back to this in <a href="#probing-the-learning-objective">the next subsection</a>.</p> <h3 id="probing-the-learning-objective">Probing the learning objective</h3> <p>If you are still puzzled about how Eq.\eqref{eq:deno_eps_match} is related to learning the score, there is a way to probe exactly what the network is learning at an arbitrary input point \(\tilde{x}\). We note that the clean sample \(x\) and the noisy sample \(\tilde{x}\) come from a joint distribution that factorizes</p> \[q(x, \tilde{x}) = q(\tilde{x} \vert x) q_{data}(x) = \mathcal{N}(\tilde{x}; x, \sigma I) q_{data}(x).\] <p>We then factorize this joint in a slightly different way, i.e.</p> \[q(x, \tilde{x}) = q(x \vert \tilde{x}) q(\tilde{x})\] <p>where \(q(x \vert \tilde{x})\) can be thought of as a distribution of all clean samples which could’ve led to the given \(\tilde{x}\). Eq.\eqref{eq:deno_eps_match} can therefore be written as</p> \[\begin{eqnarray*} J_{\mathrm{D}}(\theta) &amp;=&amp; \mathbb{E}_{(x, \tilde{x}) \sim q(x,\tilde{x})}\left[ \frac{1}{2\sigma^2} \left|\left| \epsilon_{\theta}(\tilde{x}) - \epsilon \right|\right|^2 \right] \\ &amp;=&amp; \mathbb{E}_{\tilde{x} \sim q(\tilde{x}), x \sim q(x\vert \tilde{x})}\left[ \frac{1}{2\sigma^2} \left|\left| \epsilon_{\theta}(\tilde{x}) - \frac{\tilde{x} - x}{\sigma} \right|\right|^2 \right] \\ &amp;=&amp; \mathbb{E}_{\tilde{x} \sim q(\tilde{x})}\left[ \frac{1}{2\sigma^2} \left|\left| \epsilon_{\theta}(\tilde{x}) - \frac{\tilde{x} - \mathbb{E}_{x \sim q(x\vert \tilde{x})}[x]}{\sigma} \right|\right|^2 \right] \\ \end{eqnarray*}\] <p>In the last step, the expectation \(\mathbb{E}_{q(x\vert\tilde{x})}\left[ \cdot \right]\) was pushed inside, up until the only quantity that involves \(x\). Looking at it, you may realize that the network \(\epsilon_{\theta}\), given an input \(\tilde{x}\), learns the <em>average noise direction</em> that leads to the given input point \(\tilde{x}\). It also exposes the quantity \(\mathbb{E}_{x \sim q(x\vert \tilde{x})}[x]\), which is the <em>average clean sample</em> that led to the given \(\tilde{x}\).</p> <p>Below we visualize this process with a toy example, followed by a short explanation.</p> <center> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/probing_deno_estimation.gif-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/probing_deno_estimation.gif-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/probing_deno_estimation.gif-1400.webp"/> <img src="/2024/assets/img/2024-05-07-diffusion-theory-from-scratch/probing_deno_estimation.gif" class="col-10" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </center> <p>Explanation: We have 10 data points \(x\sim q_{data}(x)\) in two clusters (big red dots) and we run the learning process by generating noisy samples \(\tilde{x}\sim q(\tilde{x})\) (small red dots). Instead of learning a neural mapping over the entire space, we learn a tabular map with only three chosen input points \(\tilde{x}_1, \tilde{x}_2, \tilde{x}_3\) (blue, magenta and green cross). Every time we sample one of those<d-footnote>Practically it's impossible to randomly sample a specific point. So we assume a little ball around each point.</d-footnote> three chosen input points, we note which input data point it came from (shown by connecting a dotted line of same color) and maintain a running average (bold cross of same color) of them, i.e. which is nothing but \(\mathbb{E}_{x \sim q(x\vert \tilde{x})}[x]\). We also show the average noise direction at each \(\tilde{x}\), i.e. \(\frac{\tilde{x} - \mathbb{E}_{x \sim q(x\vert \tilde{x})}[x]}{\sigma}\), with gray arrows. The gray arrows, as the training progresses, start to resemble the score estimate of the data.</p> <h3 id="denoising-as-inverse-problem">Denoising as inverse problem</h3> <p>A similar treatment, when applied on Eq.\eqref{eq:deno_endpoint_match}, yields the following</p> \[\begin{eqnarray*} J_{\mathrm{D}}(\theta) &amp;=&amp; \mathbb{E}_{(x, \tilde{x}) \sim q(x,\tilde{x})}\left[ \frac{1}{2\sigma^4} \left|\left| {\color{blue}x_{\theta}}(\tilde{x}) - x \right|\right|^2 \right] \\ &amp;=&amp; \mathbb{E}_{\tilde{x} \sim q(\tilde{x})}\left[ \frac{1}{2\sigma^4} \left|\left| {\color{blue}\tilde{x} + \sigma^2 s_{\theta}}(\tilde{x}) - \mathbb{E}_{x \sim q(x\vert \tilde{x})}[x] \right|\right|^2 \right] \\ \end{eqnarray*}\] <p>Notice that I brought back the original form of \(x_{\theta}(\cdot)\) that involves the score. If we had the true score instead of an learned estimate, we would have</p> \[\mathbb{E}_{x \sim q(x\vert \tilde{x})}[x] = \tilde{x} + \sigma^2 \nabla_{\tilde{x}} \log p(\tilde{x})\] <p>In “Inverse problem” and Bayesian literature, this is a very well celebrated result named “<em>Tweedie’s Formula</em>”, first published by Robbins <d-cite key="robbins1992empirical"></d-cite> but credited to statistician Maurice Tweedie. This theorem is applied in the context of bayesian posterior estimation of a “true” quantity \(x\) which we only observe through a (gaussian) noisy measurement \(\tilde{x}\). Tweedie’s formula tells us that the <em>posterior mean</em> of the inverse problem \(q(x\vert \tilde{x})\) can be computed without ever knowing the actually density, as long as we have access to the score at the noisy measurement.</p> <h4 id="summary-1">Summary</h4> <p>In this section, we explored the problem of scalable score matching. We looked at the notable attempts in the literature and learned that score can be estimated from samples only. We also looked at several interpretations of the learning objective and the connections they expose.</p> <h2 id="last-few-bits">Last few bits</h2> <h4 id="incorporating-time">Incorporating time</h4> <p>In the last section, we expressed and explained everything in terms of one known noise level \(\sigma\) and the noisy sample \(\tilde{x}\). We did so to avoid cluttering of multiple concepts that aren’t necessary to explain each other. In <a href="#estimating-the-score-is-hard">a previous section</a> however, we learned that the score must be estimated along every timestep of the forward process. By simply augmenting Eq.\eqref{eq:deno_score_match} with an additional time variable \(t \in \mathcal{U}[0, 1]\) is sufficient to induce the time dependency in the score matching problem</p> <p>\begin{equation} \label{eq:deno_score_match_with_time} J_{\mathrm{D}}(\theta) = \mathbb{E}_{x_0, \epsilon, t \sim \mathcal{U}[0, 1], x_t\sim q_t(x_t\vert x_0) }\left[ \frac{1}{2} \left|\left| s_{\theta}(x_t, t) - (- \frac{\epsilon}{\sigma_t}) \right|\right|^2 \right] \end{equation}</p> <p>.. where \(q_t(x_t \vert x_0)\) is defined in a <a href="#the-forward-process">previous section</a> and \(\sigma_t\) is the standard deviation of it.</p> <h4 id="we-took-an-different-approach">We took an different approach</h4> <p>We would like to highlight that, in this article, we first explored the reverse process and then showed why the forward process emerges out of necessity. Typical diffusion models papers start from a forward process specification of the form</p> \[dx_t = f(t)x_t dt + g(t) {dB}_t\] <p>.. and then use Anderson’s SDE reversal <d-cite key="ANDERSON1982313"></d-cite> to explain the reverse process, which also involves the score</p> \[dx_t = \left[ f(t) x_t - g(t)^2 \underbrace{\nabla_{x_t} \log q_t(x_t)}_{s_{\theta}(x_t, t)} \right] dt + g(t) dB_t\] <p>We argue that our approach is more “organic” in the sense that it builds up the theory <em>chronologically</em>, exploring the exact path the community went through over time.</p> <h4 id="conclusion">Conclusion</h4> <p>In this article, we dived deep into the theoretical fundamentals of Diffusion Models, which are often ignored by practitioners. We started from the ‘heart’ of diffusion models, i.e. scores, and built the concepts up almost chronologically. We hope this article will serve as a conceptual guide toward understanding diffusion models from the score SDE perspective. We intentionally avoid the ‘probabilistic markov model’ view of diffusion since more and more works have been seen to embrace the SDE formalism.</p>]]></content><author><name>Ayan Das</name></author><summary type="html"><![CDATA[Diffusion Models, a new generative model family, have taken the world by storm after the seminal paper by Ho et al. [2020]. While diffusion models are often described as a probabilistic Markov Chains, their underlying principle is based on the decade-old theory of Stochastic Differential Equations (SDE), as found out later by Song et al. [2021]. In this article, we will go back and revisit the 'fundamental ingredients' behind the SDE formulation and show how the idea can be 'shaped' to get to the modern form of Score-based Diffusion Models. We'll start from the very definition of the 'score', how it was used in the context of generative modeling, how we achieve the necessary theoretical guarantees and how the critical design choices were made to finally arrive at the more 'principled' framework of Score-based Diffusion. Throughout this article, we provide several intuitive illustrations for ease of understanding.]]></summary></entry><entry><title type="html">Sample Blog Post</title><link href="https://dasayan05.github.io/2024/blog/distill-example/" rel="alternate" type="text/html" title="Sample Blog Post"/><published>2024-05-07T00:00:00+02:00</published><updated>2024-05-07T00:00:00+02:00</updated><id>https://dasayan05.github.io/2024/blog/distill-example</id><content type="html" xml:base="https://dasayan05.github.io/2024/blog/distill-example/"><![CDATA[<p>Note: please use the table of contents as defined in the front matter rather than the traditional markdown styling.</p> <h2 id="equations">Equations</h2> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/">MathJax 3</a> engine. You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph. Here is an example:</p> \[\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)\] <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php">on par with KaTeX</a>.</p> <h2 id="images-and-figures">Images and Figures</h2> <p>Its generally a better idea to avoid linking to images hosted elsewhere - links can break and you might face losing important information in your blog post. To include images in your submission in this way, you must do something like the following:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% include figure.html path="assets/img/2024-05-07-distill-example/iclr.png" class="img-fluid" %}
</code></pre></div></div> <p>which results in the following image:</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/iclr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/iclr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/iclr-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/iclr.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>To ensure that there are no namespace conflicts, you must save your asset to your unique directory <code class="language-plaintext highlighter-rouge">/assets/img/2024-05-07-[SUBMISSION NAME]</code> within your submission.</p> <p>Please avoid using the direct markdown method of embedding images; they may not be properly resized. Some more complex ways to load images (note the different styles of the shapes/shadows):</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/9-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/9-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/9-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/9.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/7.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between image rows, after each row, or doesn't have to be there at all. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/8-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/8-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/8-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/8.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/10-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/10-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/10-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/10.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/11-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/11.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/12-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/12-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/12-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/12.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/7.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3 id="interactive-figures">Interactive Figures</h3> <p>Here’s how you could embed interactive figures that have been exported as HTML files. Note that we will be using plotly for this demo, but anything built off of HTML should work (<strong>no extra javascript is allowed!</strong>). All that’s required is for you to export your figure into HTML format, and make sure that the file exists in the <code class="language-plaintext highlighter-rouge">assets/html/[SUBMISSION NAME]/</code> directory in this repository’s root directory. To embed it into any page, simply insert the following code anywhere into your page.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% include [FIGURE_NAME].html %} 
</code></pre></div></div> <p>For example, the following code can be used to generate the figure underneath it.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">density_mapbox</span><span class="p">(</span>
    <span class="n">df</span><span class="p">,</span> <span class="n">lat</span><span class="o">=</span><span class="sh">'</span><span class="s">Latitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="sh">'</span><span class="s">Longitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="sh">'</span><span class="s">Magnitude</span><span class="sh">'</span><span class="p">,</span> <span class="n">radius</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">center</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">lat</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="mi">180</span><span class="p">),</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mapbox_style</span><span class="o">=</span><span class="sh">"</span><span class="s">stamen-terrain</span><span class="sh">"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">fig</span><span class="p">.</span><span class="nf">write_html</span><span class="p">(</span><span class="sh">'</span><span class="s">./assets/html/2024-05-07-distill-example/plotly_demo_1.html</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>And then include it with the following:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"l-page"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;iframe</span> <span class="na">src=</span><span class="s">"{{ 'assets/html/2024-05-07-distill-example/plotly_demo_1.html' | relative_url }}"</span> <span class="na">frameborder=</span><span class="s">'0'</span> <span class="na">scrolling=</span><span class="s">'no'</span> <span class="na">height=</span><span class="s">"600px"</span> <span class="na">width=</span><span class="s">"100%"</span><span class="nt">&gt;&lt;/iframe&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> <p>Voila!</p> <div class="l-page"> <iframe src="/2024/assets/html/2024-05-07-distill-example/plotly_demo_1.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <h2 id="citations">Citations</h2> <p>Citations are then used in the article body with the <code class="language-plaintext highlighter-rouge">&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas.</p> <p>The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it.</p> <p>Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well — the authors are human and it’s nice for them to have the community associate them with their work.</p> <hr/> <h2 id="footnotes">Footnotes</h2> <p>Just wrap the text you would like to show up in a footnote in a <code class="language-plaintext highlighter-rouge">&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote></p> <hr/> <h2 id="code-blocks">Code Blocks</h2> <p>This theme implements a built-in Jekyll feature, the use of Rouge, for syntax highlighting. It supports more than 100 languages. This example is in C++. All you have to do is wrap your code in a liquid tag:</p> <p>{% highlight c++ linenos %} <br/> code code code <br/> {% endhighlight %}</p> <p>The keyword <code class="language-plaintext highlighter-rouge">linenos</code> triggers display of line numbers. You can try toggling it on or off yourself below:</p> <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="err">\</span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> <hr/> <h2 id="diagrams">Diagrams</h2> <p>This theme supports generating various diagrams from a text description using <a href="https://github.com/zhustec/jekyll-diagrams" target="\_blank">jekyll-diagrams</a> plugin. Below, we generate a few examples of such diagrams using languages such as <a href="https://mermaid-js.github.io/mermaid/" target="\_blank">mermaid</a>, <a href="https://plantuml.com/" target="\_blank">plantuml</a>, <a href="https://vega.github.io/vega-lite/" target="\_blank">vega-lite</a>, etc.</p> <p><strong>Note:</strong> different diagram-generation packages require external dependencies to be installed on your machine. Also, be mindful of that because of diagram generation the first time you build your Jekyll website after adding new diagrams will be SLOW. For any other details, please refer to <a href="https://github.com/zhustec/jekyll-diagrams" target="\_blank">jekyll-diagrams</a> README.</p> <p><strong>Note:</strong> This is not supported for local rendering!</p> <p>The diagram below was generated by the following code:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% mermaid %}
sequenceDiagram
    participant John
    participant Alice
    Alice-&gt;&gt;John: Hello John, how are you?
    John--&gt;&gt;Alice: Great!
{% endmermaid %}
</code></pre></div></div> <div class="jekyll-diagrams diagrams mermaid"> <svg id="mermaid-1709110430898" width="100%" xmlns="http://www.w3.org/2000/svg" height="100%" style="max-width:450px;" viewBox="-50 -10 450 231"><style>#mermaid-1709110430898 .label{font-family:trebuchet ms,verdana,arial;color:#333}#mermaid-1709110430898 .node circle,#mermaid-1709110430898 .node ellipse,#mermaid-1709110430898 .node polygon,#mermaid-1709110430898 .node rect{fill:#ececff;stroke:#9370db;stroke-width:1px}#mermaid-1709110430898 .node.clickable{cursor:pointer}#mermaid-1709110430898 .arrowheadPath{fill:#333}#mermaid-1709110430898 .edgePath .path{stroke:#333;stroke-width:1.5px}#mermaid-1709110430898 .edgeLabel{background-color:#e8e8e8}#mermaid-1709110430898 .cluster rect{fill:#ffffde!important;stroke:#aa3!important;stroke-width:1px!important}#mermaid-1709110430898 .cluster text{fill:#333}#mermaid-1709110430898 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:trebuchet ms,verdana,arial;font-size:12px;background:#ffffde;border:1px solid #aa3;border-radius:2px;pointer-events:none;z-index:100}#mermaid-1709110430898 .actor{stroke:#ccf;fill:#ececff}#mermaid-1709110430898 text.actor{fill:#000;stroke:none}#mermaid-1709110430898 .actor-line{stroke:grey}#mermaid-1709110430898 .messageLine0{marker-end:"url(#arrowhead)"}#mermaid-1709110430898 .messageLine0,#mermaid-1709110430898 .messageLine1{stroke-width:1.5;stroke-dasharray:"2 2";stroke:#333}#mermaid-1709110430898 #arrowhead{fill:#333}#mermaid-1709110430898 #crosshead path{fill:#333!important;stroke:#333!important}#mermaid-1709110430898 .messageText{fill:#333;stroke:none}#mermaid-1709110430898 .labelBox{stroke:#ccf;fill:#ececff}#mermaid-1709110430898 .labelText,#mermaid-1709110430898 .loopText{fill:#000;stroke:none}#mermaid-1709110430898 .loopLine{stroke-width:2;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#ccf}#mermaid-1709110430898 .note{stroke:#aa3;fill:#fff5ad}#mermaid-1709110430898 .noteText{fill:#000;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:14px}#mermaid-1709110430898 .section{stroke:none;opacity:.2}#mermaid-1709110430898 .section0{fill:rgba(102,102,255,.49)}#mermaid-1709110430898 .section2{fill:#fff400}#mermaid-1709110430898 .section1,#mermaid-1709110430898 .section3{fill:#fff;opacity:.2}#mermaid-1709110430898 .sectionTitle0,#mermaid-1709110430898 .sectionTitle1,#mermaid-1709110430898 .sectionTitle2,#mermaid-1709110430898 .sectionTitle3{fill:#333}#mermaid-1709110430898 .sectionTitle{text-anchor:start;font-size:11px;text-height:14px}#mermaid-1709110430898 .grid .tick{stroke:#d3d3d3;opacity:.3;shape-rendering:crispEdges}#mermaid-1709110430898 .grid path{stroke-width:0}#mermaid-1709110430898 .today{fill:none;stroke:red;stroke-width:2px}#mermaid-1709110430898 .task{stroke-width:2}#mermaid-1709110430898 .taskText{text-anchor:middle;font-size:11px}#mermaid-1709110430898 .taskTextOutsideRight{fill:#000;text-anchor:start;font-size:11px}#mermaid-1709110430898 .taskTextOutsideLeft{fill:#000;text-anchor:end;font-size:11px}#mermaid-1709110430898 .taskText0,#mermaid-1709110430898 .taskText1,#mermaid-1709110430898 .taskText2,#mermaid-1709110430898 .taskText3{fill:#fff}#mermaid-1709110430898 .task0,#mermaid-1709110430898 .task1,#mermaid-1709110430898 .task2,#mermaid-1709110430898 .task3{fill:#8a90dd;stroke:#534fbc}#mermaid-1709110430898 .taskTextOutside0,#mermaid-1709110430898 .taskTextOutside1,#mermaid-1709110430898 .taskTextOutside2,#mermaid-1709110430898 .taskTextOutside3{fill:#000}#mermaid-1709110430898 .active0,#mermaid-1709110430898 .active1,#mermaid-1709110430898 .active2,#mermaid-1709110430898 .active3{fill:#bfc7ff;stroke:#534fbc}#mermaid-1709110430898 .activeText0,#mermaid-1709110430898 .activeText1,#mermaid-1709110430898 .activeText2,#mermaid-1709110430898 .activeText3{fill:#000!important}#mermaid-1709110430898 .done0,#mermaid-1709110430898 .done1,#mermaid-1709110430898 .done2,#mermaid-1709110430898 .done3{stroke:grey;fill:#d3d3d3;stroke-width:2}#mermaid-1709110430898 .doneText0,#mermaid-1709110430898 .doneText1,#mermaid-1709110430898 .doneText2,#mermaid-1709110430898 .doneText3{fill:#000!important}#mermaid-1709110430898 .crit0,#mermaid-1709110430898 .crit1,#mermaid-1709110430898 .crit2,#mermaid-1709110430898 .crit3{stroke:#f88;fill:red;stroke-width:2}#mermaid-1709110430898 .activeCrit0,#mermaid-1709110430898 .activeCrit1,#mermaid-1709110430898 .activeCrit2,#mermaid-1709110430898 .activeCrit3{stroke:#f88;fill:#bfc7ff;stroke-width:2}#mermaid-1709110430898 .doneCrit0,#mermaid-1709110430898 .doneCrit1,#mermaid-1709110430898 .doneCrit2,#mermaid-1709110430898 .doneCrit3{stroke:#f88;fill:#d3d3d3;stroke-width:2;cursor:pointer;shape-rendering:crispEdges}#mermaid-1709110430898 .activeCritText0,#mermaid-1709110430898 .activeCritText1,#mermaid-1709110430898 .activeCritText2,#mermaid-1709110430898 .activeCritText3,#mermaid-1709110430898 .doneCritText0,#mermaid-1709110430898 .doneCritText1,#mermaid-1709110430898 .doneCritText2,#mermaid-1709110430898 .doneCritText3{fill:#000!important}#mermaid-1709110430898 .titleText{text-anchor:middle;font-size:18px;fill:#000}
#mermaid-1709110430898 g.classGroup text{fill:#9370db;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:10px}#mermaid-1709110430898 g.classGroup rect{fill:#ececff;stroke:#9370db}#mermaid-1709110430898 g.classGroup line{stroke:#9370db;stroke-width:1}#mermaid-1709110430898 .classLabel .box{stroke:none;stroke-width:0;fill:#ececff;opacity:.5}#mermaid-1709110430898 .classLabel .label{fill:#9370db;font-size:10px}#mermaid-1709110430898 .relation{stroke:#9370db;stroke-width:1;fill:none}#mermaid-1709110430898 #compositionEnd,#mermaid-1709110430898 #compositionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1709110430898 #aggregationEnd,#mermaid-1709110430898 #aggregationStart{fill:#ececff;stroke:#9370db;stroke-width:1}#mermaid-1709110430898 #dependencyEnd,#mermaid-1709110430898 #dependencyStart,#mermaid-1709110430898 #extensionEnd,#mermaid-1709110430898 #extensionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1709110430898 .branch-label,#mermaid-1709110430898 .commit-id,#mermaid-1709110430898 .commit-msg{fill:#d3d3d3;color:#d3d3d3}</style><style>#mermaid-1709110430898{color:#000;font:normal normal 400 normal 16px / normal "Times New Roman"}</style><g></g><g><line id="actor0" x1="75" y1="5" x2="75" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="0" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><line id="actor1" x1="275" y1="5" x2="275" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="200" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g><defs><marker id="arrowhead" refX="5" refY="2" markerWidth="6" markerHeight="4" orient="auto"><path d="M 0,0 V 4 L6,2 Z"></path></marker></defs><defs><marker id="crosshead" markerWidth="15" markerHeight="8" orient="auto" refX="16" refY="4"><path fill="black" stroke="#000000" stroke-width="1px" d="M 9,2 V 6 L16,4 Z" style="stroke-dasharray: 0, 0;"></path><path fill="none" stroke="#000000" stroke-width="1px" d="M 0,1 L 6,7 M 6,1 L 0,7" style="stroke-dasharray: 0, 0;"></path></marker></defs><g><text x="175" y="93" class="messageText" style="text-anchor: middle;">Hello John, how are you?</text><line x1="275" y1="100" x2="75" y2="100" class="messageLine0" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="fill: none;"></line></g><g><text x="175" y="128" class="messageText" style="text-anchor: middle;">Great!</text><line x1="75" y1="135" x2="275" y2="135" class="messageLine1" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="stroke-dasharray: 3, 3; fill: none;"></line></g><g><rect x="0" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><rect x="200" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g></svg> </div> <hr/> <h2 id="tweets">Tweets</h2> <p>An example of displaying a tweet:</p> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="sv" dir="ltr">jekyll-twitter-plugin (1.0.0): A Liquid tag plugin for Jekyll that renders Tweets from Twitter API <a href="http://t.co/m4EIQPM9h4">http://t.co/m4EIQPM9h4</a></p>&mdash; RubyGems (@rubygems) <a href="https://twitter.com/rubygems/status/518821243320287232?ref_src=twsrc%5Etfw">October 5, 2014</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>An example of pulling from a timeline:</p> <div class="jekyll-twitter-plugin"><a class="twitter-timeline" data-width="500" data-tweet-limit="3" href="https://twitter.com/jekyllrb?ref_src=twsrc%5Etfw">Tweets by jekyllrb</a> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>For more details on using the plugin visit: <a href="https://github.com/rob-murray/jekyll-twitter-plugin">jekyll-twitter-plugin</a></p> <hr/> <h2 id="blockquotes">Blockquotes</h2> <blockquote> We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. —Anais Nin </blockquote> <hr/> <h2 id="layouts">Layouts</h2> <p>The main text column is referred to as the body. It is the assumed layout of any direct descendants of the <code class="language-plaintext highlighter-rouge">d-article</code> element.</p> <div class="fake-img l-body"> <p>.l-body</p> </div> <p>For images you want to display a little larger, try <code class="language-plaintext highlighter-rouge">.l-page</code>:</p> <div class="fake-img l-page"> <p>.l-page</p> </div> <p>All of these have an outset variant if you want to poke out from the body text a little bit. For instance:</p> <div class="fake-img l-body-outset"> <p>.l-body-outset</p> </div> <div class="fake-img l-page-outset"> <p>.l-page-outset</p> </div> <p>Occasionally you’ll want to use the full browser width. For this, use <code class="language-plaintext highlighter-rouge">.l-screen</code>. You can also inset the element a little from the edge of the browser by using the inset variant.</p> <div class="fake-img l-screen"> <p>.l-screen</p> </div> <div class="fake-img l-screen-inset"> <p>.l-screen-inset</p> </div> <p>The final layout is for marginalia, asides, and footnotes. It does not interrupt the normal flow of <code class="language-plaintext highlighter-rouge">.l-body</code>-sized text except on mobile screen sizes.</p> <div class="fake-img l-gutter"> <p>.l-gutter</p> </div> <hr/> <h2 id="other-typography">Other Typography?</h2> <p>Emphasis, aka italics, with <em>asterisks</em> (<code class="language-plaintext highlighter-rouge">*asterisks*</code>) or <em>underscores</em> (<code class="language-plaintext highlighter-rouge">_underscores_</code>).</p> <p>Strong emphasis, aka bold, with <strong>asterisks</strong> or <strong>underscores</strong>.</p> <p>Combined emphasis with <strong>asterisks and <em>underscores</em></strong>.</p> <p>Strikethrough uses two tildes. <del>Scratch this.</del></p> <ol> <li>First ordered list item</li> <li>Another item ⋅⋅* Unordered sub-list.</li> <li>Actual numbers don’t matter, just that it’s a number ⋅⋅1. Ordered sub-list</li> <li>And another item.</li> </ol> <p>⋅⋅⋅You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we’ll use three here to also align the raw Markdown).</p> <p>⋅⋅⋅To have a line break without a paragraph, you will need to use two trailing spaces.⋅⋅ ⋅⋅⋅Note that this line is separate, but within the same paragraph.⋅⋅ ⋅⋅⋅(This is contrary to the typical GFM line break behavior, where trailing spaces are not required.)</p> <ul> <li>Unordered lists can use asterisks</li> <li>Or minuses</li> <li>Or pluses</li> </ul> <p><a href="https://www.google.com">I’m an inline-style link</a></p> <p><a href="https://www.google.com" title="Google's Homepage">I’m an inline-style link with title</a></p> <p><a href="https://www.mozilla.org">I’m a reference-style link</a></p> <p><a href="../blob/master/LICENSE">I’m a relative reference to a repository file</a></p> <p><a href="http://slashdot.org">You can use numbers for reference-style link definitions</a></p> <p>Or leave it empty and use the <a href="http://www.reddit.com">link text itself</a>.</p> <p>URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <a href="http://www.example.com">http://www.example.com</a> and sometimes example.com (but not on Github, for example).</p> <p>Some text to show that the reference links can follow later.</p> <p>Here’s our logo (hover to see the title text):</p> <p>Inline-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 1"/></p> <p>Reference-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 2"/></p> <p>Inline <code class="language-plaintext highlighter-rouge">code</code> has <code class="language-plaintext highlighter-rouge">back-ticks around</code> it.</p> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">s</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">JavaScript syntax highlighting</span><span class="dl">"</span><span class="p">;</span>
<span class="nf">alert</span><span class="p">(</span><span class="nx">s</span><span class="p">);</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Python syntax highlighting</span><span class="sh">"</span>
<span class="nf">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No language indicated, so no syntax highlighting. 
But let's throw in a &lt;b&gt;tag&lt;/b&gt;.
</code></pre></div></div> <p>Colons can be used to align columns.</p> <table> <thead> <tr> <th>Tables</th> <th style="text-align: center">Are</th> <th style="text-align: right">Cool</th> </tr> </thead> <tbody> <tr> <td>col 3 is</td> <td style="text-align: center">right-aligned</td> <td style="text-align: right">$1600</td> </tr> <tr> <td>col 2 is</td> <td style="text-align: center">centered</td> <td style="text-align: right">$12</td> </tr> <tr> <td>zebra stripes</td> <td style="text-align: center">are neat</td> <td style="text-align: right">$1</td> </tr> </tbody> </table> <p>There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don’t need to make the raw Markdown line up prettily. You can also use inline Markdown.</p> <table> <thead> <tr> <th>Markdown</th> <th>Less</th> <th>Pretty</th> </tr> </thead> <tbody> <tr> <td><em>Still</em></td> <td><code class="language-plaintext highlighter-rouge">renders</code></td> <td><strong>nicely</strong></td> </tr> <tr> <td>1</td> <td>2</td> <td>3</td> </tr> </tbody> </table> <blockquote> <p>Blockquotes are very handy in email to emulate reply text. This line is part of the same quote.</p> </blockquote> <p>Quote break.</p> <blockquote> <p>This is a very long line that will still be quoted properly when it wraps. Oh boy let’s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can <em>put</em> <strong>Markdown</strong> into a blockquote.</p> </blockquote> <p>Here’s a line for us to start with.</p> <p>This line is separated from the one above by two newlines, so it will be a <em>separate paragraph</em>.</p> <p>This line is also a separate paragraph, but… This line is only separated by a single newline, so it’s a separate line in the <em>same paragraph</em>.</p>]]></content><author><name>Albert Einstein</name></author><summary type="html"><![CDATA[Your blog post's abstract. Please add your abstract or summary here and not in the main body of your text. Do not include math/latex or hyperlinks.]]></summary></entry><entry><title type="html">Sample Blog Post (HTML version)</title><link href="https://dasayan05.github.io/2024/blog/distill-example2/" rel="alternate" type="text/html" title="Sample Blog Post (HTML version)"/><published>2024-05-07T00:00:00+02:00</published><updated>2024-05-07T00:00:00+02:00</updated><id>https://dasayan05.github.io/2024/blog/distill-example2</id><content type="html" xml:base="https://dasayan05.github.io/2024/blog/distill-example2/"><![CDATA[<p> This is a sample blog post written in HTML (while the other <a href="/2024/blog/distill-example/">sample post</a> is written in Markdown). Authors have the choice to write in HTML or Markdown. While Markdown is easier to write, HTML gives you more control over the layout of your post. Furthermore, Markdown often interacts in unexpected ways with MathJax and other HTML widgets. If you are having trouble with Markdown, try writing in HTML instead. </p> <p> Note: please use the table of contents as defined in the front matter rather than the traditional markdown styling. </p> <h2 id="equations">Equations</h2> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/">MathJax 3</a> engine. You just need to surround your math expression with <code>$$</code>, like <code>$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>To use display mode, again surround your expression with <code>$$</code> and place it as a separate paragraph. Here is an example: $$ \left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right) $$ </p> <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php">on par with KaTeX</a>.</p> <h2 id="images-and-figures">Images and Figures</h2> <p>Its generally a better idea to avoid linking to images hosted elsewhere - links can break and you might face losing important information in your blog post. You can display images from this repository using the following code:</p> <pre><code>{% include figure.html path="assets/img/2024-05-07-distill-example/iclr.png" class="img-fluid" %}</code></pre> <p>which results in the following image:</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/iclr-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/iclr-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/iclr-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/iclr.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p> To ensure that there are no namespace conflicts, you must save your asset to your unique directory `/assets/img/2024-05-07-[SUBMISSION NAME]` within your submission. </p> <p> Please avoid using the direct HTML method of embedding images; they may not be properly resized. Some below complex ways to load images (note the different styles of the shapes/shadows): </p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/9-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/9-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/9-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/9.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/7.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A simple, elegant caption looks good between image rows, after each row, or doesn't have to be there at all. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/8-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/8-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/8-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/8.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/10-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/10-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/10-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/10.jpg" class="img-fluid z-depth-2" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/11-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/11-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/11-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/11.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/12-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/12-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/12-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/12.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/2024/assets/img/2024-05-07-distill-example/7-1400.webp"/> <img src="/2024/assets/img/2024-05-07-distill-example/7.jpg" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h3>Interactive Figures</h3> <p> Here's how you could embed interactive figures that have been exported as HTML files. Note that we will be using plotly for this demo, but anything built off of HTML should work. All that's required is for you to export your figure into HTML format, and make sure that the file exists in the `assets/html/[SUBMISSION NAME]/` directory in this repository's root directory. To embed it into any page, simply insert the following code anywhere into your page. </p> <pre><code>{% include [FIGURE_NAME].html %}</code></pre> <p> For example, the following code can be used to generate the figure underneath it. </p> <pre><code class="language-python">import pandas as pd
import plotly.express as px

df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv')

fig = px.density_mapbox(
    df, lat='Latitude', lon='Longitude', z='Magnitude', radius=10,
    center=dict(lat=0, lon=180), zoom=0, mapbox_style="stamen-terrain")
fig.show()

fig.write_html('./assets/html/2024-05-07-distill-example/plotly_demo_1.html')
</code></pre> And then include it with the following: <pre><code class="language-html">&lt;div class="l-page"&gt;
  &lt;iframe src="{{ 'assets/html/2024-05-07-distill-example/plotly_demo_1.html' | relative_url }}" frameborder='0' scrolling='no' height="600px" width="100%"&gt;&lt;/iframe&gt;
&lt;/div&gt;
</code></pre> Voila! <div class="l-page"> <iframe src="/2024/assets/html/2024-05-07-distill-example/plotly_demo_1.html" frameborder='0' scrolling='no' height="600px" width="100%"></iframe> </div> <h2 id="citations">Citations</h2> <p> Citations are then used in the article body with the <code>&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas. </p> <p> The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it. </p> <p> Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well - the authors are human and it's nice for them to have the community associate them with their work. </p> <h2 id="footnotes">Footnotes</h2> <p> Just wrap the text you would like to show up in a footnote in a <code>&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote> </p> <h2 id="code-blocks">Code Blocks</h2> <p> This theme implements a built-in Jekyll feature, the use of Rouge, for syntax highlighting. It supports more than 100 languages. This example is in C++. All you have to do is wrap your code in a liquid tag as follows: </p> <pre><code>
{% highlight c++ linenos %}  <br/> code code code <br/> {% endhighlight %}

</code></pre> The keyword `linenos` triggers display of line numbers. You can try toggling it on or off yourself below: <figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="k">const</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
<span class="n">string</span> <span class="n">myString</span><span class="p">;</span>

    <span class="n">cout</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="s">"input a string: "</span><span class="p">;</span>
    <span class="n">getline</span><span class="p">(</span><span class="n">cin</span><span class="p">,</span> <span class="n">myString</span><span class="p">);</span>
    <span class="kt">int</span> <span class="n">length</span> <span class="o">=</span> <span class="n">myString</span><span class="p">.</span><span class="n">length</span><span class="p">();</span>

    <span class="kt">char</span> <span class="n">charArray</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">char</span> <span class="o">*</span> <span class="p">[</span><span class="n">length</span><span class="p">];</span>

    <span class="n">charArray</span> <span class="o">=</span> <span class="n">myString</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">length</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">){</span>
        <span class="n">cout</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="n">charArray</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="s">" "</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> <h2 id="diagrams">Diagrams</h2> <p> This theme supports generating various diagrams from a text description using <a href="https://github.com/zhustec/jekyll-diagrams">jekyll-diagrams</a> plugin. Below, we generate a few examples of such diagrams using languages such as <a href="http://mermaid.js.org/">mermaid</a>, <a href="https://plantuml.com/">plantuml</a>, <a href="https://vega.github.io/vega-lite/">vega-lite</a>, etc. </p> <p> <b>Note</b>different diagram-generation packages require external dependencies to be installed on your machine. Also, be mindful of that because of diagram generation the first time you build your Jekyll website after adding new diagrams will be SLOW. For any other details, please refer to the <a href="https://github.com/zhustec/jekyll-diagrams">jekyll-diagrams</a> README. </p> <p> <b>Note:</b> This is not supported for local rendering! </p> <p> The diagram below was generated by the following code: </p> <pre><code>{% mermaid %}
sequenceDiagram
    participant John
    participant Alice
    Alice->>John: Hello John, how are you?
    John-->>Alice: Great!
{% endmermaid %}

</code></pre> <div class='jekyll-diagrams diagrams mermaid'> <svg id="mermaid-1709110431491" width="100%" xmlns="http://www.w3.org/2000/svg" height="100%" style="max-width:450px;" viewBox="-50 -10 450 231"><style>#mermaid-1709110431491 .label{font-family:trebuchet ms,verdana,arial;color:#333}#mermaid-1709110431491 .node circle,#mermaid-1709110431491 .node ellipse,#mermaid-1709110431491 .node polygon,#mermaid-1709110431491 .node rect{fill:#ececff;stroke:#9370db;stroke-width:1px}#mermaid-1709110431491 .node.clickable{cursor:pointer}#mermaid-1709110431491 .arrowheadPath{fill:#333}#mermaid-1709110431491 .edgePath .path{stroke:#333;stroke-width:1.5px}#mermaid-1709110431491 .edgeLabel{background-color:#e8e8e8}#mermaid-1709110431491 .cluster rect{fill:#ffffde!important;stroke:#aa3!important;stroke-width:1px!important}#mermaid-1709110431491 .cluster text{fill:#333}#mermaid-1709110431491 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:trebuchet ms,verdana,arial;font-size:12px;background:#ffffde;border:1px solid #aa3;border-radius:2px;pointer-events:none;z-index:100}#mermaid-1709110431491 .actor{stroke:#ccf;fill:#ececff}#mermaid-1709110431491 text.actor{fill:#000;stroke:none}#mermaid-1709110431491 .actor-line{stroke:grey}#mermaid-1709110431491 .messageLine0{marker-end:"url(#arrowhead)"}#mermaid-1709110431491 .messageLine0,#mermaid-1709110431491 .messageLine1{stroke-width:1.5;stroke-dasharray:"2 2";stroke:#333}#mermaid-1709110431491 #arrowhead{fill:#333}#mermaid-1709110431491 #crosshead path{fill:#333!important;stroke:#333!important}#mermaid-1709110431491 .messageText{fill:#333;stroke:none}#mermaid-1709110431491 .labelBox{stroke:#ccf;fill:#ececff}#mermaid-1709110431491 .labelText,#mermaid-1709110431491 .loopText{fill:#000;stroke:none}#mermaid-1709110431491 .loopLine{stroke-width:2;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#ccf}#mermaid-1709110431491 .note{stroke:#aa3;fill:#fff5ad}#mermaid-1709110431491 .noteText{fill:#000;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:14px}#mermaid-1709110431491 .section{stroke:none;opacity:.2}#mermaid-1709110431491 .section0{fill:rgba(102,102,255,.49)}#mermaid-1709110431491 .section2{fill:#fff400}#mermaid-1709110431491 .section1,#mermaid-1709110431491 .section3{fill:#fff;opacity:.2}#mermaid-1709110431491 .sectionTitle0,#mermaid-1709110431491 .sectionTitle1,#mermaid-1709110431491 .sectionTitle2,#mermaid-1709110431491 .sectionTitle3{fill:#333}#mermaid-1709110431491 .sectionTitle{text-anchor:start;font-size:11px;text-height:14px}#mermaid-1709110431491 .grid .tick{stroke:#d3d3d3;opacity:.3;shape-rendering:crispEdges}#mermaid-1709110431491 .grid path{stroke-width:0}#mermaid-1709110431491 .today{fill:none;stroke:red;stroke-width:2px}#mermaid-1709110431491 .task{stroke-width:2}#mermaid-1709110431491 .taskText{text-anchor:middle;font-size:11px}#mermaid-1709110431491 .taskTextOutsideRight{fill:#000;text-anchor:start;font-size:11px}#mermaid-1709110431491 .taskTextOutsideLeft{fill:#000;text-anchor:end;font-size:11px}#mermaid-1709110431491 .taskText0,#mermaid-1709110431491 .taskText1,#mermaid-1709110431491 .taskText2,#mermaid-1709110431491 .taskText3{fill:#fff}#mermaid-1709110431491 .task0,#mermaid-1709110431491 .task1,#mermaid-1709110431491 .task2,#mermaid-1709110431491 .task3{fill:#8a90dd;stroke:#534fbc}#mermaid-1709110431491 .taskTextOutside0,#mermaid-1709110431491 .taskTextOutside1,#mermaid-1709110431491 .taskTextOutside2,#mermaid-1709110431491 .taskTextOutside3{fill:#000}#mermaid-1709110431491 .active0,#mermaid-1709110431491 .active1,#mermaid-1709110431491 .active2,#mermaid-1709110431491 .active3{fill:#bfc7ff;stroke:#534fbc}#mermaid-1709110431491 .activeText0,#mermaid-1709110431491 .activeText1,#mermaid-1709110431491 .activeText2,#mermaid-1709110431491 .activeText3{fill:#000!important}#mermaid-1709110431491 .done0,#mermaid-1709110431491 .done1,#mermaid-1709110431491 .done2,#mermaid-1709110431491 .done3{stroke:grey;fill:#d3d3d3;stroke-width:2}#mermaid-1709110431491 .doneText0,#mermaid-1709110431491 .doneText1,#mermaid-1709110431491 .doneText2,#mermaid-1709110431491 .doneText3{fill:#000!important}#mermaid-1709110431491 .crit0,#mermaid-1709110431491 .crit1,#mermaid-1709110431491 .crit2,#mermaid-1709110431491 .crit3{stroke:#f88;fill:red;stroke-width:2}#mermaid-1709110431491 .activeCrit0,#mermaid-1709110431491 .activeCrit1,#mermaid-1709110431491 .activeCrit2,#mermaid-1709110431491 .activeCrit3{stroke:#f88;fill:#bfc7ff;stroke-width:2}#mermaid-1709110431491 .doneCrit0,#mermaid-1709110431491 .doneCrit1,#mermaid-1709110431491 .doneCrit2,#mermaid-1709110431491 .doneCrit3{stroke:#f88;fill:#d3d3d3;stroke-width:2;cursor:pointer;shape-rendering:crispEdges}#mermaid-1709110431491 .activeCritText0,#mermaid-1709110431491 .activeCritText1,#mermaid-1709110431491 .activeCritText2,#mermaid-1709110431491 .activeCritText3,#mermaid-1709110431491 .doneCritText0,#mermaid-1709110431491 .doneCritText1,#mermaid-1709110431491 .doneCritText2,#mermaid-1709110431491 .doneCritText3{fill:#000!important}#mermaid-1709110431491 .titleText{text-anchor:middle;font-size:18px;fill:#000}
#mermaid-1709110431491 g.classGroup text{fill:#9370db;stroke:none;font-family:trebuchet ms,verdana,arial;font-size:10px}#mermaid-1709110431491 g.classGroup rect{fill:#ececff;stroke:#9370db}#mermaid-1709110431491 g.classGroup line{stroke:#9370db;stroke-width:1}#mermaid-1709110431491 .classLabel .box{stroke:none;stroke-width:0;fill:#ececff;opacity:.5}#mermaid-1709110431491 .classLabel .label{fill:#9370db;font-size:10px}#mermaid-1709110431491 .relation{stroke:#9370db;stroke-width:1;fill:none}#mermaid-1709110431491 #compositionEnd,#mermaid-1709110431491 #compositionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1709110431491 #aggregationEnd,#mermaid-1709110431491 #aggregationStart{fill:#ececff;stroke:#9370db;stroke-width:1}#mermaid-1709110431491 #dependencyEnd,#mermaid-1709110431491 #dependencyStart,#mermaid-1709110431491 #extensionEnd,#mermaid-1709110431491 #extensionStart{fill:#9370db;stroke:#9370db;stroke-width:1}#mermaid-1709110431491 .branch-label,#mermaid-1709110431491 .commit-id,#mermaid-1709110431491 .commit-msg{fill:#d3d3d3;color:#d3d3d3}</style><style>#mermaid-1709110431491{color:#000;font:normal normal 400 normal 16px / normal "Times New Roman"}</style><g></g><g><line id="actor0" x1="75" y1="5" x2="75" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="0" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><line id="actor1" x1="275" y1="5" x2="275" y2="220" class="actor-line" stroke-width="0.5px" stroke="#999"></line><rect x="200" y="0" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="32.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g><defs><marker id="arrowhead" refX="5" refY="2" markerWidth="6" markerHeight="4" orient="auto"><path d="M 0,0 V 4 L6,2 Z"></path></marker></defs><defs><marker id="crosshead" markerWidth="15" markerHeight="8" orient="auto" refX="16" refY="4"><path fill="black" stroke="#000000" stroke-width="1px" d="M 9,2 V 6 L16,4 Z" style="stroke-dasharray: 0, 0;"></path><path fill="none" stroke="#000000" stroke-width="1px" d="M 0,1 L 6,7 M 6,1 L 0,7" style="stroke-dasharray: 0, 0;"></path></marker></defs><g><text x="175" y="93" class="messageText" style="text-anchor: middle;">Hello John, how are you?</text><line x1="275" y1="100" x2="75" y2="100" class="messageLine0" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="fill: none;"></line></g><g><text x="175" y="128" class="messageText" style="text-anchor: middle;">Great!</text><line x1="75" y1="135" x2="275" y2="135" class="messageLine1" stroke-width="2" stroke="black" marker-end="url(#arrowhead)" style="stroke-dasharray: 3, 3; fill: none;"></line></g><g><rect x="0" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="75" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="75" dy="0">John</tspan></text></g><g><rect x="200" y="155" fill="#eaeaea" stroke="#666" width="150" height="65" rx="3" ry="3" class="actor"></rect><text x="275" y="187.5" dominant-baseline="central" alignment-baseline="central" class="actor" style="text-anchor: middle;"><tspan x="275" dy="0">Alice</tspan></text></g></svg> </div> <h2 id="tweets">Tweets</h2> <p> An example of displaying a tweet: <div class='jekyll-twitter-plugin'><blockquote class="twitter-tweet"><p lang="sv" dir="ltr">jekyll-twitter-plugin (1.0.0): A Liquid tag plugin for Jekyll that renders Tweets from Twitter API <a href="http://t.co/m4EIQPM9h4">http://t.co/m4EIQPM9h4</a></p>&mdash; RubyGems (@rubygems) <a href="https://twitter.com/rubygems/status/518821243320287232?ref_src=twsrc%5Etfw">October 5, 2014</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </p> <p> An example of pulling from a timeline: <div class='jekyll-twitter-plugin'><a class="twitter-timeline" data-width="500" data-tweet-limit="3" href="https://twitter.com/jekyllrb?ref_src=twsrc%5Etfw">Tweets by jekyllrb</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </p> <p> For more details on using the plugin visit: <a href="https://github.com/rob-murray/jekyll-twitter-plugin">jekyll-twitter-plugin</a> </p> <h2 id="blockquotes">Blockquotes</h2> <blockquote> We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. —Anais Nin </blockquote> <h2 id="layouts">Layouts</h2> The main text column is referred to as the body. It's the assumed layout of any direct descendants of the `d-article` element. <div class="fake-img l-body"> <p>.l-body</p> </div> For images you want to display a little larger, try `.l-page`: <div class="fake-img l-page"> <p>.l-page</p> </div> All of these have an outset variant if you want to poke out from the body text a little bit. For instance: <div class="fake-img l-body-outset"> <p>.l-body-outset</p> </div> <div class="fake-img l-page-outset"> <p>.l-page-outset</p> </div> Occasionally you'll want to use the full browser width. For this, use `.l-screen`. You can also inset the element a little from the edge of the browser by using the inset variant. <div class="fake-img l-screen"> <p>.l-screen</p> </div> <div class="fake-img l-screen-inset"> <p>.l-screen-inset</p> </div> The final layout is for marginalia, asides, and footnotes. It does not interrupt the normal flow of `.l-body`-sized text except on mobile screen sizes. <div class="fake-img l-gutter"> <p>.l-gutter</p> </div> <h2 id="other-typography">Other Typography?</h2> <p> Emphasis, aka italics, with the <code>&lt;i&gt;&lt;/i&gt;</code> tag <i>emphasis</i>. </p> <p> Strong emphasis, aka bold, with <code>&lt;b&gt;&lt;/b&gt;</code> tag <b>bold</b>. </p> <p> Strikethrough ca be accomplished with the <code>&lt;s&gt;&lt;/s&gt;</code> tag. <s>Scratch this.</s> </p> <ul> <li>First ordered list item</li> <li>Another item</li> <ol> <li>Unordered sub-list. </li> </ol> <li>And another item.</li> </ul> <p> For code, the language can be specified in the class. For example, use <q>language-javascript</q> for Javascript and <q>language-python</q> for Python code. </p> <pre><code class="language-javascript">var s = "JavaScript syntax highlighting";
  alert(s);</code></pre> <pre><code class="language-python">s = "Python syntax highlighting"
  print(s)</code></pre> <pre><code class="language-python">No language indicated, so no syntax highlighting.</code></pre> <p> A table can be created with the <code>&lt;table&gt;</code> element. Below is an example </p> <table> <thead> <tr> <th>Tables</th> <th style="text-align: center">Are</th> <th style="text-align: right">Cool</th> </tr> </thead> <tbody> <tr> <td>col 3 is</td> <td style="text-align: center">right-aligned</td> <td style="text-align: right">$1600</td> </tr> <tr> <td>col 2 is</td> <td style="text-align: center">centered</td> <td style="text-align: right">$12</td> </tr> <tr> <td>zebra stripes</td> <td style="text-align: center">are neat</td> <td style="text-align: right">$1</td> </tr> </tbody> </table> <p> <blockquote>Blockquotes can be defined with the &gt;blockquote&lt; tag.</blockquote> </p>]]></content><author><name>Albert Einstein</name></author><summary type="html"><![CDATA[Your blog post's abstract. Please add your abstract or summary here and not in the main body of your text. Do not include math/latex or hyperlinks.]]></summary></entry></feed>